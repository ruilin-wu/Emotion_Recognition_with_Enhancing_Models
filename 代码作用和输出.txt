config.py: 参数配置文件
tess_pipeline.py:自动化处理音频文件，使它们符合特定的命名和组织结构，为后续的数据加载和模型训练步骤做准备
create_features.py:从每个文件中提取 MFCC并将它们保存为 .joblib 文件
neural_network.py:加载.joblib 文件，使用CNN架构训练模型H5
random_forest.py:加载.joblib 文件，使用随机森林分类器训练模型H5
live_predictions.py:使用预训练的模型H5,来对实时的音频文件进行情绪识别(属于用户端的程序)
plot_model.py:加载训练的模型H5，绘制并保存模型的结构图(属于用户端的程序)


改进思路：
改进此类项目可以从多个角度进行，具体取决于您的目标、可用资源以及您希望解决的特定问题。以下是一些可能的改进方向：

1. **数据质量和多样性**:
   - **数据增强**：通过在音频数据上应用各种技术（如噪声添加、音调变化、时间拉伸等）来人为地扩展数据集，有助于模型更好地泛化到现实世界的情况。

2. **特征工程**:
   - **探索新特征**：除了MFCCs，还有其他音频处理特征（如Chroma特征、声谱对比度等）可能对情绪识别有帮助。（完成）
   

3. **模型架构和算法**:
   - **尝试不同的模型**：除了卷积神经网络(CNN)和随机森林外，还可以尝试其他机器学习或深度学习模型，如循环神经网络(RNN)，尤其是长短期记忆网络(LSTM)或门控循环单元(GRU)，它们在处理序列数据（如音频）时表现良好。（完成）
   - **超参数调优**：使用网格搜索、随机搜索或贝叶斯优化等技术来找到模型的最佳超参数。
   - **集成学习**：通过组合多个模型的预测来提高性能（如投票分类器、堆叠等）。

4. **性能评估**:
   - **交叉验证**：使用K折交叉验证或分层K折交叉验证来更全面地评估模型的性能。（完成）
   - **混淆矩阵和其他指标**：使用混淆矩阵、ROC曲线、精确度-召回率曲线等工具来深入分析模型的性能。（完成）


  

